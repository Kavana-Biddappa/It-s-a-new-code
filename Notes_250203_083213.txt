import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, Concatenate, Flatten
from tensorflow.keras.preprocessing.sequence import pad_sequences
from sklearn.preprocessing import LabelEncoder, StandardScaler
import pandas as pd

# Load dataset
df = pd.read_csv("your_dataset.csv")

# Convert date column
df['date'] = pd.to_datetime(df['date_column'])
df['day'] = df['date'].dt.day.astype(np.float32)
df['week'] = df['date'].dt.isocalendar().week.astype(np.float32)
df['month'] = df['date'].dt.month.astype(np.float32)
df['year'] = df['date'].dt.year.astype(np.float32)
df['hour'] = df['date'].dt.hour.astype(np.float32)

# Encode categorical variables
le_category = LabelEncoder()
df['downtime_category_enc'] = le_category.fit_transform(df['downtime_category']).astype(np.int32)

le_family = LabelEncoder()
df['family_enc'] = le_family.fit_transform(df['family']).astype(np.int32)

# Tokenize downtime_desc
tokenizer = tf.keras.preprocessing.text.Tokenizer()
tokenizer.fit_on_texts(df['downtime_desc'])
desc_seq = tokenizer.texts_to_sequences(df['downtime_desc'])

# Pad sequences to ensure uniform shape
max_len = max(len(seq) for seq in desc_seq)  # Get max sequence length
desc_seq = pad_sequences(desc_seq, maxlen=max_len, padding='post')  # Pad with 0s

# Normalize numerical features
scaler = StandardScaler()
numerical_cols = ["cycle_time", "planned_downtime", "unplanned_downtime", "part_produced_tgt", "parts_produced"]
df[numerical_cols] = scaler.fit_transform(df[numerical_cols]).astype(np.float32)

# Convert DataFrames to numpy arrays for model input
time_features = df[['day', 'week', 'month', 'year', 'hour']].values.astype(np.float32)
numerical_features = df[numerical_cols].values.astype(np.float32)
category_features = df['downtime_category_enc'].values.reshape(-1, 1).astype(np.int32)
family_features = df['family_enc'].values.reshape(-1, 1).astype(np.int32)
desc_features = np.array(desc_seq).astype(np.int32)

# Define Inputs
time_inputs = Input(shape=(5,), dtype=tf.float32)
desc_inputs = Input(shape=(max_len,), dtype=tf.int32)
category_inputs = Input(shape=(1,), dtype=tf.int32)
family_inputs = Input(shape=(1,), dtype=tf.int32)
numerical_inputs = Input(shape=(5,), dtype=tf.float32)

# Embeddings
desc_embed = Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=16)(desc_inputs)
desc_lstm = LSTM(16)(desc_embed)

category_embed = Embedding(input_dim=len(le_category.classes_) + 1, output_dim=4)(category_inputs)
category_flat = Flatten()(category_embed)

family_embed = Embedding(input_dim=len(le_family.classes_) + 1, output_dim=4)(family_inputs)
family_flat = Flatten()(family_embed)

# Concatenation
merged = Concatenate()([time_inputs, desc_lstm, category_flat, family_flat, numerical_inputs])

# LSTM layer
lstm_out = LSTM(64, return_sequences=False)(tf.expand_dims(merged, axis=1))

# Output layers
output_desc = Dense(len(tokenizer.word_index) + 1, activation="softmax", name="downtime_desc")(lstm_out)
output_category = Dense(len(le_category.classes_), activation="softmax", name="downtime_category")(lstm_out)
output_family = Dense(len(le_family.classes_), activation="softmax", name="family")(lstm_out)
output_cycle_time = Dense(1, activation="linear", name="cycle_time")(lstm_out)
output_planned = Dense(1, activation="linear", name="planned_downtime")(lstm_out)
output_unplanned = Dense(1, activation="linear", name="unplanned_downtime")(lstm_out)
output_target = Dense(1, activation="linear", name="part_produced_tgt")(lstm_out)
output_produced = Dense(1, activation="linear", name="parts_produced")(lstm_out)

# Model Compilation
model = Model(inputs=[time_inputs, desc_inputs, category_inputs, family_inputs, numerical_inputs],
              outputs=[output_desc, output_category, output_family, output_cycle_time, output_planned,
                       output_unplanned, output_target, output_produced])

model.compile(optimizer="adam", loss=["sparse_categorical_crossentropy", "sparse_categorical_crossentropy",
                                      "sparse_categorical_crossentropy", "mse", "mse", "mse", "mse", "mse"],
              metrics=["accuracy"])

# Model Summary
model.summary()